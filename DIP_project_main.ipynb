{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DIP project main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFMMRurIze5u",
        "colab_type": "text"
      },
      "source": [
        "## Detection of Deep Network Generated Images Using Disparities in Color Components\n",
        "Amar kumar (Ced17i029)\n",
        " \n",
        "Saumya Prakash (Ced17i043)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otxNWourtQnq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd \n",
        "import os\n",
        "import math\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2HHLbQlyH74",
        "colab_type": "code",
        "outputId": "07d491fe-1001-43e5-b8a6-963486243d54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4SRMpcjztor",
        "colab_type": "text"
      },
      "source": [
        "# Important functions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYLpx7U5y0gM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filter1 = np.array([1,-1])\n",
        "filter2 = np.array([[1],[-1]])\n",
        "# rotates a matrix by 180 degree\n",
        "########################################\n",
        "def rotateby180(arr):\n",
        "    arr = np.transpose(arr)\n",
        "    for i,ival in enumerate(arr):\n",
        "        arr[i] = np.flipud(arr[i])\n",
        "    arr = np.transpose(arr)\n",
        "    return arr\n",
        "#########################################\n",
        "\n",
        "\n",
        "# High pass filter(1 x n)\n",
        "def HPF_row(array_of_colors,filters):\n",
        "  l1 = []\n",
        "  for row in array_of_colors:\n",
        "    a = np.convolve(row,filters,'same')\n",
        "    l1.append(a)\n",
        "  return l1\n",
        "\n",
        "\n",
        "# High pass filter(n x 1)\n",
        "########################################################\n",
        "def HPF_column(arr,filt):\n",
        "#     appending a row of 0\n",
        "    arr = np.vstack([arr, [0]*arr.shape[1]])\n",
        "    arr = rotateby180(arr)\n",
        "    l = []\n",
        "    for i in range(0,arr.shape[1]):\n",
        "        temp = []\n",
        "        for j in range(0,arr.shape[0]-1):\n",
        "            temp.append(arr[j][i]*filt[0] + arr[j+1][i]*filt[1])\n",
        "        l.append(temp)\n",
        "    m = np.transpose(l)[0]\n",
        "    m = rotateby180(m)\n",
        "    return m\n",
        "####################################################\n",
        "\n",
        "\n",
        "# Binarization of RGB residuals\n",
        "def residualToBin(residual):\n",
        "  li = []\n",
        "  for i in residual:\n",
        "    temp = []\n",
        "    for j in i:\n",
        "      if j >0:\n",
        "        temp.append(1)\n",
        "      else:\n",
        "        temp.append(0)\n",
        "    li.append(temp)\n",
        "  return np.array(li)\n",
        "\n",
        "# Truncation of chrominance residuals\n",
        "\n",
        "def residualToTrunc(residual,t):\n",
        "  li = []\n",
        "  for i in residual:\n",
        "    temp = []\n",
        "    for j in i:\n",
        "      if j >=t:\n",
        "        temp.append(t)\n",
        "      elif j<= -t:\n",
        "        temp.append(-t)\n",
        "      else:\n",
        "        temp.append(j)\n",
        "    li.append(temp)\n",
        "  return np.array(li)\n",
        "  \n",
        "# co occurence matrix\n",
        "\n",
        "def uniqCount1(a,b,matrix):\n",
        "  count = 0\n",
        "  for i,ival in enumerate(matrix):\n",
        "    for j,jval in enumerate(ival):\n",
        "      if j== np.shape(matrix)[1]-1:\n",
        "        break\n",
        "      if jval==a and matrix[i][j+1]==b:\n",
        "        count+=1\n",
        "  return count\n",
        "\n",
        "def getCoOccurenceMatrix1(matrix):\n",
        "  uniq = np.unique(matrix)\n",
        "  coMatrix=[]\n",
        "  for i in uniq:\n",
        "    temp = []\n",
        "    for j in uniq:\n",
        "      count = uniqCount1(i,j,matrix)\n",
        "      temp.append(count)\n",
        "    coMatrix.append(temp)\n",
        "  return np.array(coMatrix)\n",
        "\n",
        "#################################################################\n",
        "def uniqCount2(a,b,matrix):\n",
        "  count = 0\n",
        "  for i,ival in enumerate(matrix):\n",
        "    for j,jval in enumerate(ival):\n",
        "      if i== np.shape(matrix)[0]-1:\n",
        "        break\n",
        "      if jval==a and matrix[i+1][j]==b:\n",
        "        count+=1\n",
        "  return count\n",
        "\n",
        "\n",
        "def getCoOccurenceMatrix2(matrix):\n",
        "  uniq = np.unique(matrix)\n",
        "  coMatrix=[]\n",
        "  for i in uniq:\n",
        "    temp = []\n",
        "    for j in uniq:\n",
        "      count = uniqCount2(i,j,matrix)\n",
        "      temp.append(count)\n",
        "    coMatrix.append(temp)\n",
        "  return np.array(coMatrix)\n",
        "################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iayjRcrd0L7t",
        "colab_type": "text"
      },
      "source": [
        "# Feature Extractor function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdUoAKTjygEh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def feature_extractor(img):\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  imgHSV = cv2.cvtColor(img,cv2.COLOR_RGB2HSV)\n",
        "  imgYCbCr = cv2.cvtColor(img,cv2.COLOR_RGB2YCR_CB)\n",
        "  iR = np.array(img[:,:,0])\n",
        "  iG = np.array(img[:,:,1])\n",
        "  iB = np.array(img[:,:,2])\n",
        "  iH = np.array(imgHSV[:,:,0])\n",
        "  iS = np.array(imgHSV[:,:,1])\n",
        "  iCr = np.array(imgYCbCr[:,:,1])\n",
        "  iCb = np.array(imgYCbCr[:,:,2])\n",
        "  rR1 = HPF_row(iR,filter1)\n",
        "  rB1 = HPF_row(iB,filter1)\n",
        "  rG1 = HPF_row(iG,filter1)\n",
        "  rH1 = HPF_row(iH,filter1)\n",
        "  rS1 = HPF_row(iS,filter1)\n",
        "  rCr1 = HPF_row(iCr,filter1)\n",
        "  rCb1 = HPF_row(iCb,filter1)\n",
        "  ###########################\n",
        "  rR2 = HPF_column(iR,filter2)\n",
        "  rB2 = HPF_column(iB,filter2)\n",
        "  rG2 = HPF_column(iG,filter2)\n",
        "  rH2 = HPF_column(iH,filter2)\n",
        "  rS2 = HPF_column(iS,filter2)\n",
        "  rCr2 = HPF_column(iCr,filter2)\n",
        "  rCb2 = HPF_column(iCb,filter2)\n",
        "\n",
        "\n",
        "  #binarization\n",
        "  bR1 = residualToBin(rR1)\n",
        "  bB1 = residualToBin(rB1)\n",
        "  bG1 = residualToBin(rG1)\n",
        "  #######################\n",
        "  bR2 = residualToBin(rR2)\n",
        "  bB2 = residualToBin(rB2)\n",
        "  bG2 = residualToBin(rG2)\n",
        "\n",
        "  # assembled residual image R̂ RGB\n",
        "  # R̂ RGB = R̂ R · 2^0 + R̂ G · 2^1 + R̂ B · 2^2\n",
        "  R_RGB1 = bR1 + bG1*2 + bB1*4\n",
        "  #############################\n",
        "  R_RGB2 = bR2 + bG2*2 + bB2*4\n",
        "  # shape of R_RGB is 128 x 128\n",
        "  # Truncation of chrominance residuals\n",
        "  t = 2 # truncated thresh.\n",
        "  tH1 = residualToTrunc(rH1,t)\n",
        "  tS1 = residualToTrunc(rS1,t)\n",
        "  tCb1 = residualToTrunc(rCb1,t)\n",
        "  tCr1 = residualToTrunc(rCr1,t)\n",
        "  ##############################\n",
        "  tH2 = residualToTrunc(rH2,t)\n",
        "  tS2 = residualToTrunc(rS2,t)\n",
        "  tCb2 = residualToTrunc(rCb2,t)\n",
        "  tCr2 = residualToTrunc(rCr2,t)\n",
        "\n",
        "  coH1 = getCoOccurenceMatrix1(tH1)\n",
        "  # coH1 = coH1/np.sum(coH1)\n",
        "  coS1 = getCoOccurenceMatrix1(tS1)\n",
        "  # coS1 = coS1/np.sum(coS1)\n",
        "  coCb1 = getCoOccurenceMatrix1(tCb1)\n",
        "  # cocb1 = coCb1/np.sum(coCb1)\n",
        "  coCr1 = getCoOccurenceMatrix1(tCr1)\n",
        "  # coCr1 = coCr1/np.sum(coCr1)\n",
        "  coRGB1 = getCoOccurenceMatrix1(R_RGB1)\n",
        "  # coRGB1 = coRGB1/np.sum(coRGB1)\n",
        "  ##############################\n",
        "  coH2 = getCoOccurenceMatrix1(tH2)\n",
        "  # coH2 = coH2/np.sum(coH2)\n",
        "  coS2 = getCoOccurenceMatrix1(tS2)\n",
        "  # coS2 = coS2/np.sum(coS2)\n",
        "  coCb2 = getCoOccurenceMatrix1(tCb2)\n",
        "  # cocb2 = coCb2/np.sum(coCb2)\n",
        "  coCr2 = getCoOccurenceMatrix1(tCr2)\n",
        "  # coCr2 = coCr2/np.sum(coCr2)\n",
        "  coRGB2 = getCoOccurenceMatrix1(R_RGB2)\n",
        "  # coRGB2 = coRGB2/np.sum(coRGB2)\n",
        "  ####################################\n",
        "  coH3 = getCoOccurenceMatrix2(tH1)\n",
        "  # coH3 = coH3/np.sum(coH3)\n",
        "  coS3 = getCoOccurenceMatrix2(tS1)\n",
        "  # coS3 = coS3/np.sum(coS3)\n",
        "  coCb3 = getCoOccurenceMatrix2(tCb1)\n",
        "  # cocb3 = coCb3/np.sum(coCb3)\n",
        "  coCr3 = getCoOccurenceMatrix2(tCr1)\n",
        "  # coCr3 = coCr3/np.sum(coCr3)\n",
        "  coRGB3 = getCoOccurenceMatrix2(R_RGB1)\n",
        "  # coRGB3 = coRGB3/np.sum(coRGB3)\n",
        "  ##############################\n",
        "  coH4 = getCoOccurenceMatrix2(tH2)\n",
        "  # coH4 = coH4/np.sum(coH4)\n",
        "  coS4 = getCoOccurenceMatrix2(tS2)\n",
        "  # coS4 = coS4/np.sum(coS4)\n",
        "  coCb4 = getCoOccurenceMatrix2(tCb2)\n",
        "  # cocb4 = coCb4/np.sum(coCb4)\n",
        "  coCr4 = getCoOccurenceMatrix2(tCr2)\n",
        "  # coCr4 = coCr4/np.sum(coCr4)\n",
        "  coRGB4 = getCoOccurenceMatrix2(R_RGB2)\n",
        "  # coRGB4 = coRGB4/np.sum(coRGB4)\n",
        "\n",
        "  coH = np.mean([coH1,coH2,coH3,coH4], axis = 0)\n",
        "  coH_T = np.transpose(coH)\n",
        "  coH = coH + coH_T # making co-occurence matrix symmetric\n",
        "  coH = coH/np.sum(coH) # normalization\n",
        "  ###############################################\n",
        "  coS = np.mean([coS1,coS2,coS3,coS4], axis = 0)\n",
        "  coS_T = np.transpose(coS)\n",
        "  coS = coS + coS_T # making co-occurence matrix symmetric\n",
        "  coS = coS/np.sum(coS) # normalization\n",
        "  #################################################\n",
        "  coCb = np.mean([coCb1,coCb2,coCb3,coCb4], axis = 0)\n",
        "  coCb_T = np.transpose(coCb)\n",
        "  coCb = coCb + coCb_T # making co-occurence matrix symmetric\n",
        "  coCb = coCb/np.sum(coCb) # normalization\n",
        "  ################################################\n",
        "  coCr = np.mean([coCr1,coCr2,coCr3,coCr4], axis = 0)\n",
        "  coCr_T = np.transpose(coCr)\n",
        "  coCr = coCr + coCr_T # making co-occurence matrix symmetric\n",
        "  coCr = coCr/np.sum(coCr) # normalization\n",
        "  ###################################################\n",
        "  coRGB = np.mean([coRGB1,coRGB2,coRGB3,coRGB4], axis = 0)\n",
        "  coRGB_T = np.transpose(coRGB)\n",
        "  coRGB = coRGB + coRGB_T # making co-occurence matrix symmetric\n",
        "  coRGB = coRGB/np.sum(coRGB) # normalization\n",
        "  feature = np.concatenate([coRGB.flatten(),coH.flatten(),coS.flatten(),coCb.flatten(),coCr.flatten()])\n",
        "  \n",
        "  return feature"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYHcOg1f0W6R",
        "colab_type": "text"
      },
      "source": [
        "# Generating 500 Real image and 500 Fake image feature vector and saving to drive\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2RJ0rwd2t9U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generating 500 real image feature vector\n",
        "data = []\n",
        "path = \"/content/drive/My Drive/Colab Notebooks/dataset/cropped/img_align_celeba\"\n",
        "dirs = os.listdir(path)\n",
        "print(len(dirs))\n",
        "count=0\n",
        "for item in dirs:\n",
        "  count+=1\n",
        "  if(count==501):\n",
        "    break\n",
        "  print(count)\n",
        "  fullpath = os.path.join(path,item)         #corrected\n",
        "  # print(fullpath)\n",
        "  if os.path.isfile(fullpath):\n",
        "    imgtemp = cv2.imread('/content/drive/My Drive/Colab Notebooks/dataset/cropped/img_align_celeba/'+str(item))\n",
        "    # print(\"start\")\n",
        "    data.append(feature_extractor(imgtemp))\n",
        "    # print(\"end\")\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "y=[]\n",
        "for i in data:\n",
        "  y.append(0)\n",
        "df['y']=y\n",
        "df.to_csv('/content/drive/My Drive/Colab Notebooks/dataset/featuresReal_amarCo.csv')\n",
        "\n",
        "# Generating 500 fake image feature vector\n",
        "\n",
        "data2 = []\n",
        "path = \"/content/drive/My Drive/Colab Notebooks/dataset/dataset_celebA\"\n",
        "dirs = os.listdir(path)\n",
        "print(len(dirs))\n",
        "count=0\n",
        "for item in dirs:\n",
        "  count+=1\n",
        "  if(count==501):\n",
        "    break\n",
        "  print(count)\n",
        "  fullpath = os.path.join(path,item)         #corrected\n",
        "  # print(fullpath)\n",
        "  if os.path.isfile(fullpath):\n",
        "    imgtemp = cv2.imread('/content/drive/My Drive/Colab Notebooks/dataset/dataset_celebA/'+str(item))\n",
        "    # print(\"start\")\n",
        "    data2.append(feature_extractor(imgtemp))\n",
        "    # print(\"end\")\n",
        "df2 = pd.DataFrame(data2)\n",
        "y=[]\n",
        "for i in data2:\n",
        "  y.append(1)\n",
        "df2['y']=y\n",
        "df2.to_csv('/content/drive/My Drive/Colab Notebooks/dataset/featuresFake_amarCo.csv')\n",
        "df2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPhsPPVe0jfw",
        "colab_type": "text"
      },
      "source": [
        "# Importing generated feature vector from drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-Ro6Xg3VKTF",
        "colab_type": "code",
        "outputId": "1156a531-fed9-4c21-f528-c0d6bc23bee7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        }
      },
      "source": [
        "# loading saved features \n",
        "real = pd.read_csv('/content/drive/My Drive/Colab Notebooks/dataset/featuresReal_amarCo.csv')\n",
        "fake = pd.read_csv('/content/drive/My Drive/Colab Notebooks/dataset/featuresFake_amarCo.csv')\n",
        "df = real\n",
        "df2 = fake\n",
        "df"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>...</th>\n",
              "      <th>125</th>\n",
              "      <th>126</th>\n",
              "      <th>127</th>\n",
              "      <th>128</th>\n",
              "      <th>129</th>\n",
              "      <th>130</th>\n",
              "      <th>131</th>\n",
              "      <th>132</th>\n",
              "      <th>133</th>\n",
              "      <th>134</th>\n",
              "      <th>135</th>\n",
              "      <th>136</th>\n",
              "      <th>137</th>\n",
              "      <th>138</th>\n",
              "      <th>139</th>\n",
              "      <th>140</th>\n",
              "      <th>141</th>\n",
              "      <th>142</th>\n",
              "      <th>143</th>\n",
              "      <th>144</th>\n",
              "      <th>145</th>\n",
              "      <th>146</th>\n",
              "      <th>147</th>\n",
              "      <th>148</th>\n",
              "      <th>149</th>\n",
              "      <th>150</th>\n",
              "      <th>151</th>\n",
              "      <th>152</th>\n",
              "      <th>153</th>\n",
              "      <th>154</th>\n",
              "      <th>155</th>\n",
              "      <th>156</th>\n",
              "      <th>157</th>\n",
              "      <th>158</th>\n",
              "      <th>159</th>\n",
              "      <th>160</th>\n",
              "      <th>161</th>\n",
              "      <th>162</th>\n",
              "      <th>163</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.334523</td>\n",
              "      <td>0.012219</td>\n",
              "      <td>0.006997</td>\n",
              "      <td>0.007720</td>\n",
              "      <td>0.011519</td>\n",
              "      <td>0.004744</td>\n",
              "      <td>0.007128</td>\n",
              "      <td>0.097272</td>\n",
              "      <td>0.012219</td>\n",
              "      <td>0.005383</td>\n",
              "      <td>0.000607</td>\n",
              "      <td>0.001553</td>\n",
              "      <td>0.000454</td>\n",
              "      <td>0.001130</td>\n",
              "      <td>0.000154</td>\n",
              "      <td>0.007636</td>\n",
              "      <td>0.006997</td>\n",
              "      <td>0.000607</td>\n",
              "      <td>0.001784</td>\n",
              "      <td>0.000707</td>\n",
              "      <td>0.000423</td>\n",
              "      <td>0.000384</td>\n",
              "      <td>0.000830</td>\n",
              "      <td>0.003360</td>\n",
              "      <td>0.007720</td>\n",
              "      <td>0.001553</td>\n",
              "      <td>0.000707</td>\n",
              "      <td>0.003368</td>\n",
              "      <td>0.000169</td>\n",
              "      <td>0.000469</td>\n",
              "      <td>0.000208</td>\n",
              "      <td>0.010227</td>\n",
              "      <td>0.011519</td>\n",
              "      <td>0.000454</td>\n",
              "      <td>0.000423</td>\n",
              "      <td>0.000169</td>\n",
              "      <td>0.005244</td>\n",
              "      <td>0.001038</td>\n",
              "      <td>0.001292</td>\n",
              "      <td>...</td>\n",
              "      <td>0.078302</td>\n",
              "      <td>0.394962</td>\n",
              "      <td>0.063315</td>\n",
              "      <td>0.004052</td>\n",
              "      <td>0.000830</td>\n",
              "      <td>0.007151</td>\n",
              "      <td>0.063315</td>\n",
              "      <td>0.074726</td>\n",
              "      <td>0.011596</td>\n",
              "      <td>0.000938</td>\n",
              "      <td>0.001084</td>\n",
              "      <td>0.004052</td>\n",
              "      <td>0.011596</td>\n",
              "      <td>0.041277</td>\n",
              "      <td>0.044061</td>\n",
              "      <td>0.014218</td>\n",
              "      <td>0.003491</td>\n",
              "      <td>0.000546</td>\n",
              "      <td>0.000108</td>\n",
              "      <td>0.014218</td>\n",
              "      <td>0.077710</td>\n",
              "      <td>0.058724</td>\n",
              "      <td>0.006682</td>\n",
              "      <td>0.000592</td>\n",
              "      <td>0.003491</td>\n",
              "      <td>0.058724</td>\n",
              "      <td>0.382720</td>\n",
              "      <td>0.073934</td>\n",
              "      <td>0.004321</td>\n",
              "      <td>0.000546</td>\n",
              "      <td>0.006682</td>\n",
              "      <td>0.073934</td>\n",
              "      <td>0.104761</td>\n",
              "      <td>0.015348</td>\n",
              "      <td>0.000108</td>\n",
              "      <td>0.000592</td>\n",
              "      <td>0.004321</td>\n",
              "      <td>0.015348</td>\n",
              "      <td>0.034818</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.323188</td>\n",
              "      <td>0.014356</td>\n",
              "      <td>0.005644</td>\n",
              "      <td>0.007220</td>\n",
              "      <td>0.008681</td>\n",
              "      <td>0.004914</td>\n",
              "      <td>0.005890</td>\n",
              "      <td>0.117018</td>\n",
              "      <td>0.014356</td>\n",
              "      <td>0.006828</td>\n",
              "      <td>0.000254</td>\n",
              "      <td>0.002953</td>\n",
              "      <td>0.000254</td>\n",
              "      <td>0.000938</td>\n",
              "      <td>0.000054</td>\n",
              "      <td>0.006944</td>\n",
              "      <td>0.005644</td>\n",
              "      <td>0.000254</td>\n",
              "      <td>0.001492</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.000215</td>\n",
              "      <td>0.000069</td>\n",
              "      <td>0.000546</td>\n",
              "      <td>0.004621</td>\n",
              "      <td>0.007220</td>\n",
              "      <td>0.002953</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.003137</td>\n",
              "      <td>0.000062</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>0.000169</td>\n",
              "      <td>0.007367</td>\n",
              "      <td>0.008681</td>\n",
              "      <td>0.000254</td>\n",
              "      <td>0.000215</td>\n",
              "      <td>0.000062</td>\n",
              "      <td>0.003245</td>\n",
              "      <td>0.000607</td>\n",
              "      <td>0.001461</td>\n",
              "      <td>...</td>\n",
              "      <td>0.079017</td>\n",
              "      <td>0.311193</td>\n",
              "      <td>0.072396</td>\n",
              "      <td>0.003260</td>\n",
              "      <td>0.000254</td>\n",
              "      <td>0.006221</td>\n",
              "      <td>0.072396</td>\n",
              "      <td>0.105792</td>\n",
              "      <td>0.013080</td>\n",
              "      <td>0.000377</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>0.003260</td>\n",
              "      <td>0.013080</td>\n",
              "      <td>0.028082</td>\n",
              "      <td>0.035679</td>\n",
              "      <td>0.013587</td>\n",
              "      <td>0.003768</td>\n",
              "      <td>0.000577</td>\n",
              "      <td>0.000277</td>\n",
              "      <td>0.013587</td>\n",
              "      <td>0.098256</td>\n",
              "      <td>0.071897</td>\n",
              "      <td>0.006436</td>\n",
              "      <td>0.000454</td>\n",
              "      <td>0.003768</td>\n",
              "      <td>0.071897</td>\n",
              "      <td>0.302288</td>\n",
              "      <td>0.076456</td>\n",
              "      <td>0.004460</td>\n",
              "      <td>0.000577</td>\n",
              "      <td>0.006436</td>\n",
              "      <td>0.076456</td>\n",
              "      <td>0.104223</td>\n",
              "      <td>0.018547</td>\n",
              "      <td>0.000277</td>\n",
              "      <td>0.000454</td>\n",
              "      <td>0.004460</td>\n",
              "      <td>0.018547</td>\n",
              "      <td>0.066637</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.267901</td>\n",
              "      <td>0.021707</td>\n",
              "      <td>0.010504</td>\n",
              "      <td>0.007836</td>\n",
              "      <td>0.016994</td>\n",
              "      <td>0.005675</td>\n",
              "      <td>0.014072</td>\n",
              "      <td>0.075910</td>\n",
              "      <td>0.021707</td>\n",
              "      <td>0.023314</td>\n",
              "      <td>0.001053</td>\n",
              "      <td>0.007144</td>\n",
              "      <td>0.000638</td>\n",
              "      <td>0.002491</td>\n",
              "      <td>0.000331</td>\n",
              "      <td>0.012511</td>\n",
              "      <td>0.010504</td>\n",
              "      <td>0.001053</td>\n",
              "      <td>0.005675</td>\n",
              "      <td>0.000923</td>\n",
              "      <td>0.001407</td>\n",
              "      <td>0.000254</td>\n",
              "      <td>0.002461</td>\n",
              "      <td>0.004375</td>\n",
              "      <td>0.007836</td>\n",
              "      <td>0.007144</td>\n",
              "      <td>0.000923</td>\n",
              "      <td>0.008828</td>\n",
              "      <td>0.000092</td>\n",
              "      <td>0.000692</td>\n",
              "      <td>0.000292</td>\n",
              "      <td>0.012126</td>\n",
              "      <td>0.016994</td>\n",
              "      <td>0.000638</td>\n",
              "      <td>0.001407</td>\n",
              "      <td>0.000092</td>\n",
              "      <td>0.011580</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.006390</td>\n",
              "      <td>...</td>\n",
              "      <td>0.069013</td>\n",
              "      <td>0.282742</td>\n",
              "      <td>0.064922</td>\n",
              "      <td>0.004906</td>\n",
              "      <td>0.000838</td>\n",
              "      <td>0.007436</td>\n",
              "      <td>0.064922</td>\n",
              "      <td>0.092996</td>\n",
              "      <td>0.019700</td>\n",
              "      <td>0.000638</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>0.004906</td>\n",
              "      <td>0.019700</td>\n",
              "      <td>0.079355</td>\n",
              "      <td>0.115727</td>\n",
              "      <td>0.024007</td>\n",
              "      <td>0.006997</td>\n",
              "      <td>0.001269</td>\n",
              "      <td>0.000769</td>\n",
              "      <td>0.024007</td>\n",
              "      <td>0.088583</td>\n",
              "      <td>0.059463</td>\n",
              "      <td>0.007497</td>\n",
              "      <td>0.001584</td>\n",
              "      <td>0.006997</td>\n",
              "      <td>0.059463</td>\n",
              "      <td>0.216320</td>\n",
              "      <td>0.059055</td>\n",
              "      <td>0.006859</td>\n",
              "      <td>0.001269</td>\n",
              "      <td>0.007497</td>\n",
              "      <td>0.059055</td>\n",
              "      <td>0.089229</td>\n",
              "      <td>0.024022</td>\n",
              "      <td>0.000769</td>\n",
              "      <td>0.001584</td>\n",
              "      <td>0.006859</td>\n",
              "      <td>0.024022</td>\n",
              "      <td>0.107099</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.315607</td>\n",
              "      <td>0.008904</td>\n",
              "      <td>0.003345</td>\n",
              "      <td>0.007128</td>\n",
              "      <td>0.007359</td>\n",
              "      <td>0.002430</td>\n",
              "      <td>0.006175</td>\n",
              "      <td>0.122578</td>\n",
              "      <td>0.008904</td>\n",
              "      <td>0.003430</td>\n",
              "      <td>0.000138</td>\n",
              "      <td>0.002015</td>\n",
              "      <td>0.000108</td>\n",
              "      <td>0.000384</td>\n",
              "      <td>0.000038</td>\n",
              "      <td>0.006698</td>\n",
              "      <td>0.003345</td>\n",
              "      <td>0.000138</td>\n",
              "      <td>0.000677</td>\n",
              "      <td>0.000261</td>\n",
              "      <td>0.000131</td>\n",
              "      <td>0.000085</td>\n",
              "      <td>0.000292</td>\n",
              "      <td>0.002276</td>\n",
              "      <td>0.007128</td>\n",
              "      <td>0.002015</td>\n",
              "      <td>0.000261</td>\n",
              "      <td>0.003583</td>\n",
              "      <td>0.000046</td>\n",
              "      <td>0.000161</td>\n",
              "      <td>0.000038</td>\n",
              "      <td>0.008551</td>\n",
              "      <td>0.007359</td>\n",
              "      <td>0.000108</td>\n",
              "      <td>0.000131</td>\n",
              "      <td>0.000046</td>\n",
              "      <td>0.001784</td>\n",
              "      <td>0.000369</td>\n",
              "      <td>0.001546</td>\n",
              "      <td>...</td>\n",
              "      <td>0.053619</td>\n",
              "      <td>0.416569</td>\n",
              "      <td>0.055426</td>\n",
              "      <td>0.004560</td>\n",
              "      <td>0.001238</td>\n",
              "      <td>0.004591</td>\n",
              "      <td>0.055426</td>\n",
              "      <td>0.085215</td>\n",
              "      <td>0.017947</td>\n",
              "      <td>0.001207</td>\n",
              "      <td>0.001138</td>\n",
              "      <td>0.004560</td>\n",
              "      <td>0.017947</td>\n",
              "      <td>0.047598</td>\n",
              "      <td>0.053334</td>\n",
              "      <td>0.018670</td>\n",
              "      <td>0.004075</td>\n",
              "      <td>0.000654</td>\n",
              "      <td>0.000169</td>\n",
              "      <td>0.018670</td>\n",
              "      <td>0.085922</td>\n",
              "      <td>0.052511</td>\n",
              "      <td>0.005037</td>\n",
              "      <td>0.000577</td>\n",
              "      <td>0.004075</td>\n",
              "      <td>0.052511</td>\n",
              "      <td>0.412940</td>\n",
              "      <td>0.049197</td>\n",
              "      <td>0.003699</td>\n",
              "      <td>0.000654</td>\n",
              "      <td>0.005037</td>\n",
              "      <td>0.049197</td>\n",
              "      <td>0.082646</td>\n",
              "      <td>0.016894</td>\n",
              "      <td>0.000169</td>\n",
              "      <td>0.000577</td>\n",
              "      <td>0.003699</td>\n",
              "      <td>0.016894</td>\n",
              "      <td>0.062192</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.306625</td>\n",
              "      <td>0.014918</td>\n",
              "      <td>0.007543</td>\n",
              "      <td>0.006659</td>\n",
              "      <td>0.010788</td>\n",
              "      <td>0.004990</td>\n",
              "      <td>0.009212</td>\n",
              "      <td>0.124054</td>\n",
              "      <td>0.014918</td>\n",
              "      <td>0.007843</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>0.001707</td>\n",
              "      <td>0.000331</td>\n",
              "      <td>0.002222</td>\n",
              "      <td>0.000115</td>\n",
              "      <td>0.008635</td>\n",
              "      <td>0.007543</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>0.001907</td>\n",
              "      <td>0.000454</td>\n",
              "      <td>0.000631</td>\n",
              "      <td>0.000115</td>\n",
              "      <td>0.001392</td>\n",
              "      <td>0.003929</td>\n",
              "      <td>0.006659</td>\n",
              "      <td>0.001707</td>\n",
              "      <td>0.000454</td>\n",
              "      <td>0.001984</td>\n",
              "      <td>0.000123</td>\n",
              "      <td>0.000638</td>\n",
              "      <td>0.000154</td>\n",
              "      <td>0.007643</td>\n",
              "      <td>0.010788</td>\n",
              "      <td>0.000331</td>\n",
              "      <td>0.000631</td>\n",
              "      <td>0.000123</td>\n",
              "      <td>0.003445</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>0.001707</td>\n",
              "      <td>...</td>\n",
              "      <td>0.077887</td>\n",
              "      <td>0.352685</td>\n",
              "      <td>0.069344</td>\n",
              "      <td>0.006467</td>\n",
              "      <td>0.000607</td>\n",
              "      <td>0.005775</td>\n",
              "      <td>0.069344</td>\n",
              "      <td>0.088121</td>\n",
              "      <td>0.014641</td>\n",
              "      <td>0.000208</td>\n",
              "      <td>0.000754</td>\n",
              "      <td>0.006467</td>\n",
              "      <td>0.014641</td>\n",
              "      <td>0.045691</td>\n",
              "      <td>0.052258</td>\n",
              "      <td>0.019731</td>\n",
              "      <td>0.003929</td>\n",
              "      <td>0.000454</td>\n",
              "      <td>0.000046</td>\n",
              "      <td>0.019731</td>\n",
              "      <td>0.104208</td>\n",
              "      <td>0.070882</td>\n",
              "      <td>0.006090</td>\n",
              "      <td>0.000508</td>\n",
              "      <td>0.003929</td>\n",
              "      <td>0.070882</td>\n",
              "      <td>0.274406</td>\n",
              "      <td>0.073688</td>\n",
              "      <td>0.005321</td>\n",
              "      <td>0.000454</td>\n",
              "      <td>0.006090</td>\n",
              "      <td>0.073688</td>\n",
              "      <td>0.115803</td>\n",
              "      <td>0.020293</td>\n",
              "      <td>0.000046</td>\n",
              "      <td>0.000508</td>\n",
              "      <td>0.005321</td>\n",
              "      <td>0.020293</td>\n",
              "      <td>0.051443</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>495</td>\n",
              "      <td>0.265640</td>\n",
              "      <td>0.013595</td>\n",
              "      <td>0.009496</td>\n",
              "      <td>0.011211</td>\n",
              "      <td>0.018147</td>\n",
              "      <td>0.004352</td>\n",
              "      <td>0.011403</td>\n",
              "      <td>0.075341</td>\n",
              "      <td>0.013595</td>\n",
              "      <td>0.011934</td>\n",
              "      <td>0.000484</td>\n",
              "      <td>0.006713</td>\n",
              "      <td>0.000431</td>\n",
              "      <td>0.001499</td>\n",
              "      <td>0.000161</td>\n",
              "      <td>0.012872</td>\n",
              "      <td>0.009496</td>\n",
              "      <td>0.000484</td>\n",
              "      <td>0.002245</td>\n",
              "      <td>0.001100</td>\n",
              "      <td>0.000784</td>\n",
              "      <td>0.000231</td>\n",
              "      <td>0.001492</td>\n",
              "      <td>0.004560</td>\n",
              "      <td>0.011211</td>\n",
              "      <td>0.006713</td>\n",
              "      <td>0.001100</td>\n",
              "      <td>0.017824</td>\n",
              "      <td>0.000231</td>\n",
              "      <td>0.000869</td>\n",
              "      <td>0.000338</td>\n",
              "      <td>0.023976</td>\n",
              "      <td>0.018147</td>\n",
              "      <td>0.000431</td>\n",
              "      <td>0.000784</td>\n",
              "      <td>0.000231</td>\n",
              "      <td>0.009074</td>\n",
              "      <td>0.001023</td>\n",
              "      <td>0.003699</td>\n",
              "      <td>...</td>\n",
              "      <td>0.067237</td>\n",
              "      <td>0.263780</td>\n",
              "      <td>0.060939</td>\n",
              "      <td>0.005398</td>\n",
              "      <td>0.001246</td>\n",
              "      <td>0.006751</td>\n",
              "      <td>0.060939</td>\n",
              "      <td>0.094888</td>\n",
              "      <td>0.020961</td>\n",
              "      <td>0.001100</td>\n",
              "      <td>0.001730</td>\n",
              "      <td>0.005398</td>\n",
              "      <td>0.020961</td>\n",
              "      <td>0.063115</td>\n",
              "      <td>0.062469</td>\n",
              "      <td>0.020031</td>\n",
              "      <td>0.004937</td>\n",
              "      <td>0.000561</td>\n",
              "      <td>0.000261</td>\n",
              "      <td>0.020031</td>\n",
              "      <td>0.105223</td>\n",
              "      <td>0.064192</td>\n",
              "      <td>0.005506</td>\n",
              "      <td>0.000554</td>\n",
              "      <td>0.004937</td>\n",
              "      <td>0.064192</td>\n",
              "      <td>0.270239</td>\n",
              "      <td>0.066222</td>\n",
              "      <td>0.004706</td>\n",
              "      <td>0.000561</td>\n",
              "      <td>0.005506</td>\n",
              "      <td>0.066222</td>\n",
              "      <td>0.111005</td>\n",
              "      <td>0.025045</td>\n",
              "      <td>0.000261</td>\n",
              "      <td>0.000554</td>\n",
              "      <td>0.004706</td>\n",
              "      <td>0.025045</td>\n",
              "      <td>0.067037</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>496</td>\n",
              "      <td>0.335153</td>\n",
              "      <td>0.017824</td>\n",
              "      <td>0.008082</td>\n",
              "      <td>0.007936</td>\n",
              "      <td>0.017094</td>\n",
              "      <td>0.004975</td>\n",
              "      <td>0.010950</td>\n",
              "      <td>0.071389</td>\n",
              "      <td>0.017824</td>\n",
              "      <td>0.016732</td>\n",
              "      <td>0.000577</td>\n",
              "      <td>0.003714</td>\n",
              "      <td>0.000577</td>\n",
              "      <td>0.002122</td>\n",
              "      <td>0.000131</td>\n",
              "      <td>0.009566</td>\n",
              "      <td>0.008082</td>\n",
              "      <td>0.000577</td>\n",
              "      <td>0.002384</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.000185</td>\n",
              "      <td>0.001253</td>\n",
              "      <td>0.004075</td>\n",
              "      <td>0.007936</td>\n",
              "      <td>0.003714</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>0.005782</td>\n",
              "      <td>0.000123</td>\n",
              "      <td>0.000423</td>\n",
              "      <td>0.000277</td>\n",
              "      <td>0.012072</td>\n",
              "      <td>0.017094</td>\n",
              "      <td>0.000577</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.000123</td>\n",
              "      <td>0.010858</td>\n",
              "      <td>0.001307</td>\n",
              "      <td>0.004591</td>\n",
              "      <td>...</td>\n",
              "      <td>0.052112</td>\n",
              "      <td>0.322665</td>\n",
              "      <td>0.052934</td>\n",
              "      <td>0.006367</td>\n",
              "      <td>0.001115</td>\n",
              "      <td>0.005813</td>\n",
              "      <td>0.052934</td>\n",
              "      <td>0.077541</td>\n",
              "      <td>0.020831</td>\n",
              "      <td>0.000469</td>\n",
              "      <td>0.000823</td>\n",
              "      <td>0.006367</td>\n",
              "      <td>0.020831</td>\n",
              "      <td>0.094473</td>\n",
              "      <td>0.090090</td>\n",
              "      <td>0.021407</td>\n",
              "      <td>0.005452</td>\n",
              "      <td>0.000769</td>\n",
              "      <td>0.000469</td>\n",
              "      <td>0.021407</td>\n",
              "      <td>0.082354</td>\n",
              "      <td>0.058009</td>\n",
              "      <td>0.005752</td>\n",
              "      <td>0.001115</td>\n",
              "      <td>0.005452</td>\n",
              "      <td>0.058009</td>\n",
              "      <td>0.303919</td>\n",
              "      <td>0.055303</td>\n",
              "      <td>0.005952</td>\n",
              "      <td>0.000769</td>\n",
              "      <td>0.005752</td>\n",
              "      <td>0.055303</td>\n",
              "      <td>0.073850</td>\n",
              "      <td>0.020646</td>\n",
              "      <td>0.000469</td>\n",
              "      <td>0.001115</td>\n",
              "      <td>0.005952</td>\n",
              "      <td>0.020646</td>\n",
              "      <td>0.100040</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>497</td>\n",
              "      <td>0.379445</td>\n",
              "      <td>0.022123</td>\n",
              "      <td>0.018178</td>\n",
              "      <td>0.003460</td>\n",
              "      <td>0.012741</td>\n",
              "      <td>0.005552</td>\n",
              "      <td>0.013272</td>\n",
              "      <td>0.041738</td>\n",
              "      <td>0.022123</td>\n",
              "      <td>0.013826</td>\n",
              "      <td>0.000723</td>\n",
              "      <td>0.001715</td>\n",
              "      <td>0.000615</td>\n",
              "      <td>0.002499</td>\n",
              "      <td>0.000261</td>\n",
              "      <td>0.005683</td>\n",
              "      <td>0.018178</td>\n",
              "      <td>0.000723</td>\n",
              "      <td>0.012134</td>\n",
              "      <td>0.001015</td>\n",
              "      <td>0.001523</td>\n",
              "      <td>0.000246</td>\n",
              "      <td>0.004521</td>\n",
              "      <td>0.005367</td>\n",
              "      <td>0.003460</td>\n",
              "      <td>0.001715</td>\n",
              "      <td>0.001015</td>\n",
              "      <td>0.003337</td>\n",
              "      <td>0.000038</td>\n",
              "      <td>0.000277</td>\n",
              "      <td>0.000361</td>\n",
              "      <td>0.004791</td>\n",
              "      <td>0.012741</td>\n",
              "      <td>0.000615</td>\n",
              "      <td>0.001523</td>\n",
              "      <td>0.000038</td>\n",
              "      <td>0.012411</td>\n",
              "      <td>0.001092</td>\n",
              "      <td>0.005675</td>\n",
              "      <td>...</td>\n",
              "      <td>0.057225</td>\n",
              "      <td>0.494110</td>\n",
              "      <td>0.059440</td>\n",
              "      <td>0.003622</td>\n",
              "      <td>0.000223</td>\n",
              "      <td>0.003568</td>\n",
              "      <td>0.059440</td>\n",
              "      <td>0.067344</td>\n",
              "      <td>0.010196</td>\n",
              "      <td>0.000215</td>\n",
              "      <td>0.000408</td>\n",
              "      <td>0.003622</td>\n",
              "      <td>0.010196</td>\n",
              "      <td>0.059824</td>\n",
              "      <td>0.088383</td>\n",
              "      <td>0.019547</td>\n",
              "      <td>0.005183</td>\n",
              "      <td>0.000953</td>\n",
              "      <td>0.000269</td>\n",
              "      <td>0.019547</td>\n",
              "      <td>0.088214</td>\n",
              "      <td>0.062400</td>\n",
              "      <td>0.005398</td>\n",
              "      <td>0.001215</td>\n",
              "      <td>0.005183</td>\n",
              "      <td>0.062400</td>\n",
              "      <td>0.347672</td>\n",
              "      <td>0.054972</td>\n",
              "      <td>0.004614</td>\n",
              "      <td>0.000953</td>\n",
              "      <td>0.005398</td>\n",
              "      <td>0.054972</td>\n",
              "      <td>0.076156</td>\n",
              "      <td>0.017840</td>\n",
              "      <td>0.000269</td>\n",
              "      <td>0.001215</td>\n",
              "      <td>0.004614</td>\n",
              "      <td>0.017840</td>\n",
              "      <td>0.054795</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>498</td>\n",
              "      <td>0.302734</td>\n",
              "      <td>0.017840</td>\n",
              "      <td>0.011188</td>\n",
              "      <td>0.011888</td>\n",
              "      <td>0.017540</td>\n",
              "      <td>0.005775</td>\n",
              "      <td>0.007113</td>\n",
              "      <td>0.077840</td>\n",
              "      <td>0.017840</td>\n",
              "      <td>0.012180</td>\n",
              "      <td>0.000738</td>\n",
              "      <td>0.003837</td>\n",
              "      <td>0.001053</td>\n",
              "      <td>0.001738</td>\n",
              "      <td>0.000154</td>\n",
              "      <td>0.007797</td>\n",
              "      <td>0.011188</td>\n",
              "      <td>0.000738</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>0.001138</td>\n",
              "      <td>0.000830</td>\n",
              "      <td>0.000215</td>\n",
              "      <td>0.001015</td>\n",
              "      <td>0.004083</td>\n",
              "      <td>0.011888</td>\n",
              "      <td>0.003837</td>\n",
              "      <td>0.001138</td>\n",
              "      <td>0.008643</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.000269</td>\n",
              "      <td>0.000138</td>\n",
              "      <td>0.012811</td>\n",
              "      <td>0.017540</td>\n",
              "      <td>0.001053</td>\n",
              "      <td>0.000830</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.015917</td>\n",
              "      <td>0.002153</td>\n",
              "      <td>0.004506</td>\n",
              "      <td>...</td>\n",
              "      <td>0.062600</td>\n",
              "      <td>0.277682</td>\n",
              "      <td>0.061285</td>\n",
              "      <td>0.006305</td>\n",
              "      <td>0.002153</td>\n",
              "      <td>0.005767</td>\n",
              "      <td>0.061285</td>\n",
              "      <td>0.077310</td>\n",
              "      <td>0.018370</td>\n",
              "      <td>0.002999</td>\n",
              "      <td>0.001661</td>\n",
              "      <td>0.006305</td>\n",
              "      <td>0.018370</td>\n",
              "      <td>0.086291</td>\n",
              "      <td>0.068175</td>\n",
              "      <td>0.018078</td>\n",
              "      <td>0.005290</td>\n",
              "      <td>0.001469</td>\n",
              "      <td>0.000977</td>\n",
              "      <td>0.018078</td>\n",
              "      <td>0.072635</td>\n",
              "      <td>0.057079</td>\n",
              "      <td>0.006828</td>\n",
              "      <td>0.001715</td>\n",
              "      <td>0.005290</td>\n",
              "      <td>0.057079</td>\n",
              "      <td>0.334584</td>\n",
              "      <td>0.062200</td>\n",
              "      <td>0.007782</td>\n",
              "      <td>0.001469</td>\n",
              "      <td>0.006828</td>\n",
              "      <td>0.062200</td>\n",
              "      <td>0.084031</td>\n",
              "      <td>0.019178</td>\n",
              "      <td>0.000977</td>\n",
              "      <td>0.001715</td>\n",
              "      <td>0.007782</td>\n",
              "      <td>0.019178</td>\n",
              "      <td>0.079386</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>499</td>\n",
              "      <td>0.305933</td>\n",
              "      <td>0.012319</td>\n",
              "      <td>0.006190</td>\n",
              "      <td>0.005559</td>\n",
              "      <td>0.009558</td>\n",
              "      <td>0.004191</td>\n",
              "      <td>0.009258</td>\n",
              "      <td>0.114904</td>\n",
              "      <td>0.012319</td>\n",
              "      <td>0.005137</td>\n",
              "      <td>0.000177</td>\n",
              "      <td>0.001215</td>\n",
              "      <td>0.000231</td>\n",
              "      <td>0.001315</td>\n",
              "      <td>0.000038</td>\n",
              "      <td>0.008635</td>\n",
              "      <td>0.006190</td>\n",
              "      <td>0.000177</td>\n",
              "      <td>0.001338</td>\n",
              "      <td>0.000361</td>\n",
              "      <td>0.000661</td>\n",
              "      <td>0.000123</td>\n",
              "      <td>0.001323</td>\n",
              "      <td>0.003583</td>\n",
              "      <td>0.005559</td>\n",
              "      <td>0.001215</td>\n",
              "      <td>0.000361</td>\n",
              "      <td>0.001953</td>\n",
              "      <td>0.000046</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.000177</td>\n",
              "      <td>0.006698</td>\n",
              "      <td>0.009558</td>\n",
              "      <td>0.000231</td>\n",
              "      <td>0.000661</td>\n",
              "      <td>0.000046</td>\n",
              "      <td>0.004583</td>\n",
              "      <td>0.000408</td>\n",
              "      <td>0.001353</td>\n",
              "      <td>...</td>\n",
              "      <td>0.088183</td>\n",
              "      <td>0.411310</td>\n",
              "      <td>0.074134</td>\n",
              "      <td>0.004198</td>\n",
              "      <td>0.000208</td>\n",
              "      <td>0.004314</td>\n",
              "      <td>0.074134</td>\n",
              "      <td>0.090720</td>\n",
              "      <td>0.007220</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000354</td>\n",
              "      <td>0.004198</td>\n",
              "      <td>0.007220</td>\n",
              "      <td>0.013887</td>\n",
              "      <td>0.043184</td>\n",
              "      <td>0.017863</td>\n",
              "      <td>0.003353</td>\n",
              "      <td>0.000369</td>\n",
              "      <td>0.000108</td>\n",
              "      <td>0.017863</td>\n",
              "      <td>0.104408</td>\n",
              "      <td>0.067014</td>\n",
              "      <td>0.004414</td>\n",
              "      <td>0.000254</td>\n",
              "      <td>0.003353</td>\n",
              "      <td>0.067014</td>\n",
              "      <td>0.322112</td>\n",
              "      <td>0.075926</td>\n",
              "      <td>0.004575</td>\n",
              "      <td>0.000369</td>\n",
              "      <td>0.004414</td>\n",
              "      <td>0.075926</td>\n",
              "      <td>0.108729</td>\n",
              "      <td>0.015779</td>\n",
              "      <td>0.000108</td>\n",
              "      <td>0.000254</td>\n",
              "      <td>0.004575</td>\n",
              "      <td>0.015779</td>\n",
              "      <td>0.042261</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 166 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Unnamed: 0         0         1         2  ...       161       162       163  y\n",
              "0             0  0.334523  0.012219  0.006997  ...  0.004321  0.015348  0.034818  0\n",
              "1             1  0.323188  0.014356  0.005644  ...  0.004460  0.018547  0.066637  0\n",
              "2             2  0.267901  0.021707  0.010504  ...  0.006859  0.024022  0.107099  0\n",
              "3             3  0.315607  0.008904  0.003345  ...  0.003699  0.016894  0.062192  0\n",
              "4             4  0.306625  0.014918  0.007543  ...  0.005321  0.020293  0.051443  0\n",
              "..          ...       ...       ...       ...  ...       ...       ...       ... ..\n",
              "495         495  0.265640  0.013595  0.009496  ...  0.004706  0.025045  0.067037  0\n",
              "496         496  0.335153  0.017824  0.008082  ...  0.005952  0.020646  0.100040  0\n",
              "497         497  0.379445  0.022123  0.018178  ...  0.004614  0.017840  0.054795  0\n",
              "498         498  0.302734  0.017840  0.011188  ...  0.007782  0.019178  0.079386  0\n",
              "499         499  0.305933  0.012319  0.006190  ...  0.004575  0.015779  0.042261  0\n",
              "\n",
              "[500 rows x 166 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8Tu6Ren0-s0",
        "colab_type": "text"
      },
      "source": [
        "## Detection Strategies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mGeeuv9VMsF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEMEcOPR1HP6",
        "colab_type": "text"
      },
      "source": [
        "## Sample-aware detection and model-aware detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfZneDDsVOSi",
        "colab_type": "code",
        "outputId": "2bd2bd2d-a04c-4482-ac16-c0b4787b4d83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "\n",
        "concatDf = pd.concat([df,df2])\n",
        "randomDf = concatDf.sample(frac = 1)\n",
        "y = randomDf.pop('y')\n",
        "randomDf.pop('Unnamed: 0')\n",
        "print(randomDf)\n",
        "X_train, X_test,y_train,y_test = train_test_split(randomDf,y, test_size=0.1,)\n",
        "  \n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            0         1         2  ...       161       162       163\n",
            "66   0.324296  0.013849  0.006005  ...  0.004598  0.023276  0.054149\n",
            "374  0.352454  0.011596  0.010934  ...  0.004298  0.014841  0.047044\n",
            "461  0.304764  0.020070  0.012172  ...  0.007090  0.022899  0.081954\n",
            "370  0.352716  0.013295  0.006859  ...  0.005867  0.014310  0.021069\n",
            "153  0.320066  0.011527  0.012780  ...  0.007051  0.020708  0.095026\n",
            "..        ...       ...       ...  ...       ...       ...       ...\n",
            "174  0.321220  0.009343  0.004598  ...  0.005667  0.022076  0.063653\n",
            "199  0.341520  0.012465  0.007543  ...  0.005121  0.017301  0.060039\n",
            "8    0.297136  0.020731  0.013972  ...  0.008974  0.029520  0.123816\n",
            "424  0.359267  0.015117  0.008989  ...  0.004775  0.020600  0.060470\n",
            "86   0.343935  0.009727  0.005929  ...  0.005752  0.018962  0.052642\n",
            "\n",
            "[1000 rows x 164 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4RKlUe21PX8",
        "colab_type": "text"
      },
      "source": [
        "Training binary SVM classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NvGcdP_VRdm",
        "colab_type": "code",
        "outputId": "f8704ca4-0a23-4d99-f794-92fb77e76fdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "clf = svm.SVC()\n",
        "clf.fit(X_train,y_train)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E9TF1o2VT7z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res = clf.predict(X_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-FSAk5QVZUo",
        "colab_type": "code",
        "outputId": "05e55ef2-90f8-4601-9d82-16a8d2d97c7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "print(classification_report(res,y_test,target_names=['real','fake']))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        real       0.72      0.88      0.79        50\n",
            "        fake       0.85      0.66      0.74        50\n",
            "\n",
            "    accuracy                           0.77       100\n",
            "   macro avg       0.78      0.77      0.77       100\n",
            "weighted avg       0.78      0.77      0.77       100\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Hu8hYoQ11SK",
        "colab_type": "text"
      },
      "source": [
        "# Sample-aware detection\n",
        "Random image is taken from a set of fake images that were generated by known generator. \n",
        "Predict : 1 - Fake Image and 0 - Real Image\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dxd0kMqW3t1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "bd63a9b5-193b-42be-9048-2fdbd207eeb9"
      },
      "source": [
        "testImg = cv2.imread('/content/drive/My Drive/Colab Notebooks/dataset/995.jpg') #this is fake image\n",
        "feature1 = feature_extractor(testImg)\n",
        "feature1 = feature1.reshape(-1,1)\n",
        "# print(feature1.shape)\n",
        "feature1 = feature1.T\n",
        "\n",
        "dftest = pd.DataFrame(feature1)\n",
        "# print(dftest)\n",
        "res1 = clf.predict(dftest)\n",
        "print(res1)\n",
        "\n",
        "testImg = cv2.imread('/content/drive/My Drive/Colab Notebooks/dataset/cropped/img_align_celeba/004040.jpg') \n",
        "#above is real image\n",
        "feature1 = feature_extractor(testImg)\n",
        "feature1 = feature1.reshape(-1,1)\n",
        "# print(feature1.shape)\n",
        "feature1 = feature1.T\n",
        "\n",
        "dftest = pd.DataFrame(feature1)\n",
        "# print(dftest)\n",
        "res1 = clf.predict(dftest)\n",
        "print(res1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1]\n",
            "[0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BFPcGVh3CIe",
        "colab_type": "text"
      },
      "source": [
        "# Model-aware detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7c4xD581sOa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "real = pd.read_csv('/content/drive/My Drive/Colab Notebooks/dataset/featuresReal_amarCo.csv')\n",
        "fake = pd.read_csv('/content/drive/My Drive/Colab Notebooks/dataset/featuresFake_amarCo.csv')\n",
        "real.pop('Unnamed: 0')\n",
        "fake.pop('Unnamed: 0')\n",
        "real1 = real.iloc[:450,:]\n",
        "real2 = real.iloc[450:,:]\n",
        "fake1 = fake.iloc[:450,:]\n",
        "fake2 = fake.iloc[450:,:]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbPW0zlU4q-B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "concatDf = pd.concat([real1,fake1])\n",
        "randomDf = concatDf.sample(frac = 1)\n",
        "\n",
        "y = randomDf.pop('y')\n",
        "X_train, X_test,y_train,y_test = train_test_split(randomDf,y, test_size=0.1,)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29vETKIE45aV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "c1b800c4-716f-457a-cf67-d0dcded98756"
      },
      "source": [
        "clf = svm.SVC()\n",
        "clf.fit(X_train,y_train)\n",
        "res = clf.predict(X_test)\n",
        "print(classification_report(res,y_test,target_names=['real','fake']))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        real       0.89      0.95      0.92        42\n",
            "        fake       0.96      0.90      0.92        48\n",
            "\n",
            "    accuracy                           0.92        90\n",
            "   macro avg       0.92      0.92      0.92        90\n",
            "weighted avg       0.92      0.92      0.92        90\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCH1JXtg8HWH",
        "colab_type": "text"
      },
      "source": [
        "Detecting fake image that were generated by known generative model but not used while traing classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RP6xIxFW5Bsm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "625fa5c6-6829-4b9e-cfea-e6d73ed79d96"
      },
      "source": [
        "real1 = real.iloc[:450,:]\n",
        "real2 = real.iloc[450:,:]\n",
        "fake1 = fake.iloc[:450,:]\n",
        "fake2 = fake.iloc[450:,:]\n",
        "y_test = fake2.pop('y')\n",
        "res_test = clf.predict(fake2)\n",
        "print(\"Only fake images in fake2 for model-aware\")\n",
        "print(classification_report(res_test,y_test,target_names=['real','fake']))\n",
        "print('no real image present so precision is 0')"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Only fake images in fake2 for model-aware\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        real       0.00      0.00      0.00         4\n",
            "        fake       0.92      1.00      0.96        46\n",
            "\n",
            "    accuracy                           0.92        50\n",
            "   macro avg       0.46      0.50      0.48        50\n",
            "weighted avg       0.85      0.92      0.88        50\n",
            "\n",
            "no real image present so precision is 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THJdp2IR-JCQ",
        "colab_type": "text"
      },
      "source": [
        "# Model-unaware detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xR48PXNU5tyA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "real = pd.read_csv('/content/drive/My Drive/Colab Notebooks/dataset/featuresReal_amarCo.csv')\n",
        "fake = pd.read_csv('/content/drive/My Drive/Colab Notebooks/dataset/featuresFake_amarCo.csv')\n",
        "\n",
        "fake1 = fake.iloc[299,:]\n",
        "\n",
        "real.pop('Unnamed: 0')\n",
        "fake1.pop('Unnamed: 0')\n",
        "\n",
        "y_fake1 = fake1.pop('y')\n",
        "\n",
        "real1 = real.iloc[:490,:]\n",
        "real2 = real.iloc[490:,:]\n",
        "y_real1 = real1.pop('y')\n",
        "y_real2 = real2.pop('y')\n",
        "\n",
        "fake1 = pd.DataFrame(fake1)\n",
        "fake1 = fake1.T\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDY-Wi1vLpI0",
        "colab_type": "text"
      },
      "source": [
        "Trainig one-class classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZC5o3hIGHv3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4043007c-ac56-4340-d7fa-bc40cb9fe2e5"
      },
      "source": [
        "# print(pd.DataFrame(fake1))\n",
        "\n",
        "clf = svm.OneClassSVM(nu=0.1, kernel=\"rbf\",gamma = 'auto')\n",
        "clf.fit(real1)\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma='auto', kernel='rbf',\n",
              "            max_iter=-1, nu=0.1, shrinking=True, tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vS0i95JZLxvY",
        "colab_type": "text"
      },
      "source": [
        "predicting a fake image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkezgwG_D5dz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0e50b27e-f169-451c-8f25-2ee5686b66f1"
      },
      "source": [
        "y_pred_fake = clf.predict(fake1)\n",
        "print(y_pred_fake)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrvceFMbGuNc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}